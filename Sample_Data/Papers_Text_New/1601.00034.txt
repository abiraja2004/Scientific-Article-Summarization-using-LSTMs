





plainthmTheorem[section]
lemma[thm]Lemmaproposition[thm]PropositioncorrollaryCorollary

MyFramelinecolor=white,
    outerlinewidth=1pt,
    roundcorner=2pt,
    innertopmargin=,
    innerbottommargin=,
    innerrightmargin=5pt,
    innerleftmargin=5pt,
    backgroundcolor=gray!20!white



definitiondefinitionDefinition[section]
conjectureConjecture[section]
exampleExample[section]

remarkremRemarknoteNote#1 [[ todo: #1 ]]


@#!T
Stochastic Neural Networks with Monotonic Activation Functions
@#^T
[1]Siamak Ravanbakhsh, Barnabás Póczos, Jeff Schneider[2]
Dale Schuurmans, Russell Greiner[1]Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA 15213[2]University of Alberta, Edmonton, AB T6G 2E8, Canada

thefnmarkfootnotetext





[



]




@#!A

We propose a Laplace approximation that creates a stochastic unit 
from any smooth monotonic activation function, using only Gaussian noise. 
This paper investigates the application of this stochastic approximation
in training a family of Restricted Boltzmann Machines (RBM) that are closely
linked to Bregman divergences.  
This family, that we call exponential family RBM (Exp-RBM),
is a subset of the exponential family Harmoniums that expresses
family members 
through a choice of smooth monotonic 
non-linearity for each neuron.
Using contrastive divergence along with our Gaussian approximation, we show that  
Exp-RBM can learn useful representations using novel stochastic units.

@#^A



@#!S
Introduction
@#^S
 Appearing in Proceedings of the 19th International Conference
on Artificial Intelligence and Statistics (AISTATS)
2016, Cadiz, Spain. JMLR: W&CP volume 41. Copyright
2016 by the authors
Deep neural networks lecun2015deep,bengio2009learning have produced some of the best results in complex pattern recognition tasks where the training data is abundant. 
Here, we are interested in deep learning for generative modeling.
Recent years has witnessed a surge of interest in directed generative models that are 
trained using (stochastic) back-propagation [][]kingma2013auto,rezende2014stochastic,goodfellow2014generative.
These models are distinct from deep energy-based models -- including deep Boltzmann machine hinton2006fast and (convolutional) deep belief network salakhutdinov2009deep,lee2009convolutional -- that rely on a bipartite graphical model called restricted Boltzmann machine (RBM) in each layer. Although, due to their use of Gaussian noise, the stochastic units that we introduce in this paper can be potentially used with stochastic back-propagation, this paper is limited to applications in RBM.


To this day, the choice of stochastic units in RBM has been constrained to well-known members of the exponential family; in the past RBMs have used units with Bernoulli smolensky1986information, Gaussian freund1994unsupervised,marks2001diffusion, categorical welling2004exponential, Gamma welling2002learning and Poisson gehler2006rate conditional distributions.
The exception to this specialization, is the Rectified Linear Unit that was introduced with a (heuristic) sampling procedure nair2010rectified.


This limitation of RBM to well-known exponential family members is despite the fact that welling2004exponential 
introduced a generalization of RBMs, called Exponential Family Harmoniums (EFH), 
covering a large subset of exponential family with bipartite structure. 
The architecture of EFH does not suggest a procedure connecting the EFH to arbitrary non-linearities and more importantly a general sampling procedure is missing.[
As the concluding remarks of welling2004exponential suggest, this capability is indeed desirable:"A future challenge is therefore to start the modelling process with the desired non-linearity and to subsequently introduce auxiliary variables to facilitate inference and learning."]
We introduce a useful subset of the EFH, which we 
call exponential family RBMs (Exp-RBMs), 
with an approximate sampling procedure addressing these shortcomings.

The basic idea in Exp-RBM is simple: restrict the sufficient statistics to identity function. This allows definition of each unit using only its mean stochastic activation, which is the non-linearity of the neuron.
With this restriction, not only we gain interpretability, but also trainability; 
we show that it is possible to efficiently sample the activation of these stochastic neurons and train the resulting model using contrastive divergence.
Interestingly, this restriction also closely relates the generative training of Exp-RBM to  
 discriminative training using the matching loss and its regularization by noise injection.

In the following, sec:model introduces the Exp-RBM family and
sec:learning investigates learning of Exp-RBMs via an efficient approximate sampling procedure. 
Here, we also establish connections to discriminative training and
produce an interpretation of stochastic units in Exp-RBMs as an infinite collection of 
Bernoulli units with different activation biases. 
sec:experiments demonstrates the effectiveness of
the proposed sampling procedure, when combined with contrastive divergence training, in data representation.


@#!S
The Model
@#^S


The conventional RBM models the joint probability 
(, |) for visible variables  = [_1,...,_i,...,_I] with ∈_1 ×...×_I  and hidden variables  = [_1,...,_j,..._J] with ∈_1 ×...×_J as
(, |) = (-(,) - ()).

This joint probability is a Boltzmann distribution with a particular energy function : ×→ and a normalization function A.
The distinguishing property of RBM compared to other Boltzmann distributions is the conditional independence due to its bipartite structure. 
welling2004exponential construct Exponential Family Harmoniums (EFH), by first 
constructing independent distribution over individual variables: considering a hidden variable _j, its sufficient statistics {t_b}_b  and
canonical parameters {η̃_j,b}_b, this independent distribution is
(_j) = (_j) (∑_bη̃_j,b  t_b(_j) -({η̃_j,b}_b) )

where : _j → is the base measure and ({η_i,a}_a)
is the normalization constant. 
Here, for notational convenience, we are assuming functions with distinct inputs are distinct --  
t_b(_j) is not necessarily the same function as t_b(_j'), for j' ≠ j.

The authors then combine these independent distributions using quadratic terms that reflect the bipartite structure of the EFH to get its joint form
(, ) ∝ &(∑_i,aν̃_i,a t_a(_i) 

+ &∑_j,bη̃_j,b  t_b(_j) + ∑_i,a,j,b_i,j^a,b t_a(_i) t_b(_j) ) 
where the normalization function is ignored and the base measures are represented as additional sufficient statistics with fixed parameters. In this model, the conditional distributions are 
(_i |) = ( ∑_aν_i,a t_a(_j) -({ν_i,a}_a )
(_j |) = ( ∑_bη_j,b t_b(_j) -({η_j,b}_b )

where the shifted parameters η_j,b = η̃_j,b + ∑_i,a_i,j^a,b t_a(_i) 
and ν_i,a = ν̃_i,a + ∑_j,b_i,j^a,b t_b(_j)
incorporate the effect of evidence in network on the random variable of interest.

It is generally not possible to efficiently sample these conditionals (or the joint probability) for arbitrary sufficient statistics.
More importantly, the joint form of eq:EFH_joint and its energy function are "obscure". This is in the sense that   
the base measures {}, depend on the choice of sufficient statistics and the normalization function A(). In fact for a fixed set of sufficient statistics {t_a(_i)}_i, {t_b(_j)}_j, different compatible choices of normalization constants and base measures may produce diverse subsets of the exponential family. Exp-RBM is one such family, where sufficient statistics are identity functions. 

###TABLE###
 Stochastic units, their conditional distribution (eq:bregman_p) and the Gaussian approximation to this distribution. 
Here Li(·)
    is the polylogarithmic function and (cond.) is equal to one if the condition is satisfied and zero otherwise. ent(p) is the binary entropy function.
.7
###TABLE###

        unit name & non-linearity  (η)    & Gaussian approximation & conditional dist (|η)  
[2pt]-
        Sigmoid (Bernoulli) Unit & (1 + e^-η)^-1&      -                 & {η -  (1 + (η))}   

        Noisy Tanh Unit   & (1 + e^-η)^-1 - 1/2& ((η) , ((η) - 1/2)((η) + 1/2)) & {η - (1 + (η)) + ent() - () }

        ArcSinh Unit & (η + √(1 + η^2)) & (sinh^-1(η) , (√(1 + η^2))^-1) & {η - cosh() + √(1 + η^2) - η sin^-1(η) - () } 

        Symmetric Sqrt Unit (SymSqU)  & sign(η)√(|η|) & ((η) ,  √(|η|)/2) & {η - ||^3/3 - 2(η^2)^3/4/3 - () } 

        Linear (Gaussian) Unit & η                 & (η , 1)       & {η - 1/2(η^2) - 1/2(^2) -(√(2π)) }

        Softplus Unit & (1 + e^η) & ((η) , (1 + e^-η)^-1) & {η + Li_2(-e^η) + Li_2(e^) + (1 - e^) - (e^ - 1) - ()} 

        Rectified Linear Unit (ReLU)  & (0,η) & ((η) , (η > 0)) &  - 

        Rectified Quadratic Unit (ReQU)  & (0,η |η|) & ((η) , (η > 0) η) & - 

        Symmetric Quadratic Unit (SymQU)  & η |η| & (η |η| ,  |η|) & {η - |η|^3/3 - 2(^2)^3/4/3 - () }

        Exponential Unit  & e^η & (e^η , e^η) & {η - e^η -  ((y) - 1) - () }

        Sinh Unit & 1/2(e^η - e^-η) & (sinh(η) , cosh(η)) & {η - cosh(η) + √(1 + ^2) -  sin^-1() - () }

        Poisson Unit  & e^η & - & {η - e^η - ! } 

@@@TABLE@@@


@@@TABLE@@@



@#S!S
Bregman Divergences and Exp-RBM
@#S^S

Exp-RBM restricts the sufficient statistics t_a(_i) and t_b(_j) to single
identity functions _i, _j for all i and j. This means the RBM has a single weight matrix ∈^I × J. As before, each hidden unit j, receives an input η_j = ∑_i W_i,j_i and similarly each visible unit i receives the input ν_i = ∑_j W_i,j_j.
[Note that we ignore the "bias parameters" ν̃_i and η̃_j, since they can be encoded using the weights for additional hidden or visible units (_j = 1, _i = 1)  that are clamped to one.]


Here, the conditional distributions (_i |ν_i) and (_j |η_j) 
 have a single mean parameter, (η) ∈M, which is equal to the mean of the conditional distribution. We could freely assign any desired continuous and monotonic non-linearity : →M⊆ to represent the mapping from canonical parameter η_j to this mean parameter: (η_j) = ∫__j_j (_j |η_j) d_j.
This choice of  defines the conditionals
(_j |η_j) &= ( -_(η_j  _j) - (_j) ) 
(_i |ν_i) &= ( -_(ν_i   _i) - (_i) )
where  is the base measure and _ is the Bregman divergence for the function .

The Bregman divergence bregman1967relaxation,banerjee2005clustering between _j
and η_j for a monotonically increasing transfer function (corresponding to the activation function)  is given by[
The conventional form of Bregman divergence is
_(η_j  _j ) = (η_j) - ((_j)) - _j (η_j - (_j)),
where  is the anti-derivative of .
Since  is strictly convex and differentiable, it has a Legendre-Fenchel dual
^*(_j) = _η_j〈_j, η_j〉 - (η_j).
Now, set the derivative of the r.h.s.   η_j to zero to get _j = (η_j), or η_j = (_j), where ^*(_j) is the anti-derivative of (_i). 
Using the duality to switch  and  in the above we can get ((_j)) = _j (_j) - ^*(_j). By replacing this in the original form of Bregman divergence we get the alternative form of eq:bregman.]_(η_j  _j) = - η_j _j + (η_j) + ^*(_j)

where  with /η(η_j) =  (η_j) is the anti-derivative of 
and ^* is the anti-derivative of . Substituting this expression for Bregmann divergence in
eq:bregman_p, we notice both ^* and  are functions of _j. 
In fact, these two functions are often not separated [][]mccullagh1989generalized. By separating them
we see that some times,  simplifies to a constant, enabling us to approximate eq:bregman_p in sec:sampling.




  Let (η_j) = η_j be a linear neuron. Then (η_j) = 1/2η_j^2 and 
  ^*(_j) = 1/2_j^2, giving a Gaussian conditional distribution
  (_j |η_j) = e^- 1/2( _j - η_j)^2  + (_j)  , where 
  (_j) = (√(2π)) is a constant. 





@#S!S
The Joint Form
@#S^S

So far we have defined the conditional distribution of our Exp-RBM as members of, 
using a single mean parameter (η_j) (or (ν_i) for visible units) that represents the activation function of the neuron. Now we would like to find the corresponding joint form and the energy function.
The problem of relating the local conditionals to the joint form in graphical models goes back to the work of besag1974spatial.It is easy to check that, using the more general treatment of yang2012graphical, 
the joint form corresponding to the conditional of eq:bregman_p is 

  &(, |)   =   ( ^T ··

 &- ∑_i(^*(_i) + (_i)) 
 - ∑_j(^*(_j) + (_j) ) - ()  ) 
where () is the joint normalization constant. It is noteworthy that only the anti-derivative of , ^* appears in the joint form and  is absent.  
From this, the energy function is
 
   &(, ) = 
  - ^T ··

 &+ ∑_i(^*(_i) + (_i)) + ∑_j(^*(_j) + (_j) ).  For the sigmoid non-linearity (η_j) = 1/1 + e^-η_j, 
  we have (η_j) = (1 + e^η_j) and ^*(_j) = (1 - _j)(1 - _j) + _j (_j) is the negative entropy.
  Since _j ∈{0, 1} only takes extreme values, the negative entropy  ^*(_j) evaluates to zero: 

###FORMULA###
(_j |η_j) =  ( _j η_j - (1 + (η_j)) - (_j))

@@@FORMULA@@@
Separately evaluating this expression for _j = 0 and _j = 1, shows that the above conditional is a well-defined distribution for (_j) = 0, and in 
fact it turns out to be the sigmoid function itself --  
  (_j = 1 |η_j) = 1/1 + e^-η_j. 
When all conditionals in the RBM are of the form eq:sigmoid_p --  for a binary RBM with a sigmoid non-linearity, since {(η_j)}_j and {(ν_i)}_i do not appear in the joint form eq:joint and ^*(0) = ^*(1) = 0, the joint form has the simple and the familiar form 
  
  (, )   =   ( ^T ··  - ()  )
  .
      
###FIGURE###
position=top ArcSinh unit < g r a p h i c s > Sinh unit< g r a p h i c s > Softplus unit< g r a p h i c s > Exp unit< g r a p h i c s >< g r a p h i c s >< g r a p h i c s >< g r a p h i c s >< g r a p h i c s > Conditional probability of eq:approx1 for different 
    stochastic units (top row) and the Gaussian approximation of Proposition <ref> (bottom row) for the same unit. 
 Here the horizontal axis is the input η _j= ∑_i W_i,j_i and the vertical axis is the stochastic activation _j with the intensity (_j |η_j).
 see table:units for more details on these stochastic units.
@@@FIGURE@@@



@#!S
Learning
@#^S

A consistent estimator for the parameters , given observations D = {1,...,N}, is obtained by maximizing the marginal likelihood ∏_n(n|), where the eq:joint defines the joint probability (, ). 
The gradient of the log-marginal-likelihood ∇_ (∑_n((n|))  ) is 1/N∑_n_(|n, ) [· (n)^T]   -  _(, |) [ ·^T] 
where the first expectation is  the observed data 
in which (|) = ∏_j(_j |) and (_j |) is given by eq:bregman_p. The second expectation is  the model of eq:joint.

When discriminatively training a neuron (∑_i W_i,j_i) using input output pairs D={(n, _jn)}_n, 
in order to have a loss that is convex in the model parameters _:j, it is common
to use a matching loss for the given transfer function  helmbold1999relative. This is simply the Bregman divergence _((η_jn)  _jn), 
where η_jn = ∑_i W_i,j_in.
Minimizing this matching loss corresponds to maximizing the log-likelihood of eq:bregman_p,
and it should not be surprising that the gradient ∇__:j (∑_n_((η_jn)  _jn)  ) of this loss  _:j = [W_1,j,...,W_M,j] 
∑_n(η_jn) (n)^T   - _jn(n)^T

resembles that of eq:grad, where (η_jn) above substitutes _j in eq:grad.


However, note that in generative training, _j is not simply equal to (η_j), but it is sampled from the exponential family distribution eq:bregman_p with the mean (η_j) -- that is _j = (η_j) + noise.
This extends the previous observations linking the discriminative and generative (or regularized) training -- via Gaussian noise injection -- to the noise from other members of the exponential family [][]an1996effects,vincent2008extracting,bishop1995training which in turn relates to the regularizing role of generative pretraining of neural networks erhan2010does.

Our sampling scheme (next section) further suggests that
when using output Gaussian noise injection for regularization of arbitrary activation functions, the variance of this noise should be scaled by the derivative of the activation function.



@#S!S
Sampling
@#S^S

To learn the generative model, we need to be able to sample from the distributions that define the expectations in eq:grad.
Sampling from the joint model can also be reduced to alternating conditional sampling of visible and hidden variables ( block Gibbs sampling). Many methods, including contrastive divergence [CD;][]hinton2002training, stochastic maximum likelihood [ persistent CD][]tieleman2008training and their variations [][]tieleman2009using,breuleux2011quickly only require this alternating sampling
in order to optimize an approximation to the gradient of eq:grad. 
Here, we are interested in sampling from  (_j |η_j) and (_i |ν_i) as defined in eq:bregman_p, which is in general non-trivial. 
 However some members of the exponential family have relatively efficient sampling procedures ahrens1974computer. One of these members that we use in our experiments is the Poisson distribution.

  For a Poisson unit, a Poisson distribution 
  (_j |λ) = λ^_j/_j! e^-λ
  represents the probability of a neuron firing _j times in a unit of time, given its average rate 
is λ. We can define Poisson units within Exp-RBM using _j(η_j) = e^η_j, which gives (η_j) = e^η_j and 
  ^*(_j) = _j ((_j) - 1). For (_j |η_j) to be properly normalized, since _j ∈Z^+ is a non-negative integer,   
  ^*(_j) + (_j) = (_j!) ≈^*(_j) (using Sterling's approximation). This gives 
  (_j |η_j)   =   ( _jη_j - e^η_j -  (_j!) )
  which is identical to distribution of eq:poisson_dist, for λ = e^η_j. 
This means, we can use any available sampling routine for Poisson
  distribution to learn the parameters for an exponential family RBM where some units are Poisson.
In sec:experiments, we use a modified version of Knuth's method knuth1969seminumerical for Poisson sampling.


By making a simplifying assumption, the following Laplace approximation demonstrates how to use Gaussian noise to sample from general conditionals in Exp-RBM, for "any" smooth and monotonic non-linearity. 

  Assuming a constant base measure (_i) = c, the distribution of (_j   η_j ) is to the second order
approximated by a Gaussian 
  ( -_(η_j  _j) - c ) ≈( _j |(η_j), '(η_j) )
  
  where '(η_j) = /η_j(η_j) is the derivative of the activation 
  function.

  The mode (and the mean) of the conditional eq:bregman_p
  for η_j is (η_j). This is because the Bregman divergence _(η_j _j) achieves minimum when _j = (η_j).
  Now, write the Taylor series approximation to the target log-probability around its mode
  
      & ( ( + (η_j) |η_j  )) 

& = (-_(η_j  + (η_j))) - c

      & = η_j(η_j) - ^*((η_j)) - (η_j) 
 
      &+  (η_j - ((η_j))  + 1/2^2( -1/'(η_j)) + (^3) 

      &= η_j(η_j) - (η_j(η_j) - (η_j)) - (η_j) 

      &+ (η_j - η_j) + 1/2^2( -1/'(η_j)) + (^3) 

      &= -1/2^2/'(η_j)+ (^3) 
  In eq:proof1 we used the fact that / y(y) = 1/'((y))
  and in eq:proof2, we used the conjugate duality of  and ^*.
  Note that the final unnormalized log-probability in eq:proof3 is that of a Gaussian, with mean zero and variance '(η_j). Since our Taylor expansion was around (η_j), this
  gives us the approximation of eq:gaussian_sampling.





@S#S!S
Sampling Accuracy
@S#S^S

To exactly evaluate the accuracy of our sampling scheme, we need to 
evaluate the conditional distribution of eq:bregman_p.
However, we are not aware of any analytical or numeric method to estimate 
the base measure (_j). Here, we replace (_j) with (η_j),
playing the role of a normalization constant. We then evaluate   
( _j |η_j) ≈( -_(η_j  _j) - (η_j) )

where 
(η_j) is numerically approximated for each η_j value. fig:comparison_sampling compares this density  against the Gaussian approximation  
( _j |η_j) ≈( (η_j), '(η_j) ).
As the figure shows, the densities are very similar.




@#S!S
Bernoulli Ensemble Interpretation
@#S^S

This section gives an interpretation of Exp-RBM in terms of a Bernoulli RBM with an infinite collection of Bernoulli units. 
nair2010rectified introduce the softplus unit, (η_j) = (1 + e^η_j), as an approximation to the rectified linear unit (ReLU) (η_j) = (0, η_j). To have a probabilistic interpretation for this non-linearity, the authors represent it as an infinite series of
Bernoulli units with shifted bias:
(1 + e^η_j) = ∑_n = 1^∞σ(η_j - n + .5)

where σ(x) = 1/1 + e^-x is the sigmoid function. This means that the sample y_j from a softplus unit is effectively the number of active Bernoulli units. 
The authors then suggest using _j ∼(0, (η_j, σ(η_j)) to sample from this type of unit. In comparison, our Proposition <ref> suggests using  _j ∼((1 + e^η_j), σ(η_j)) for softplus and _j ∼((0, η_j), step(η_j)) -- where step(η_j) is the step function -- for ReLU. Both of these are very similar to the approximation of nair2010rectified and we found them to perform similarly in practice as well.

Note that these Gaussian approximations are assuming (η_j) is constant. 
However, by numerically approximating ∫__j(-_(η_j _j)) _j, for (η_j) = (1 + e^η_j), 
fig:softplus_error shows that the  integrals are not the same for different values of η_j, showing that the base measure (_j) is not constant for ReLU. In spite of this, experimental results for pretraining ReLU units using Gaussian noise
suggests the usefulness of this type of approximation. 
###FIGURE###
< g r a p h i c s >  Numerical approximation to the integral ∫__j(-_(η_j _j)) _j for the softplus unit (η_j) = (1 + e^η_j), at different η_j.
@@@FIGURE@@@



We can extend this interpretation as a collection of (weighted) Bernoulli units to any non-linearity . For simplicity, let us assume _η→ -∞(η) = 0 and _η→ +∞(η) = ∞[The following series and the sigmoid function need to be adjusted depending on these limits. For example, for the case where _j is antisymmetric and unbounded ( (η_j) ∈{ sinh(η_j), sinh^-1(η_j), η_j  | η_j|} ), we need to change the domain of Bernoulli units from {0,1} to {-.5,+.5}. This corresponds to changing the sigmoid to hyperbolic tangent 1/2 tanh(1/2η_j). In this case, we also need to change the bounds for n in the series of eq:series to ±∞.], and define the following series of Bernoulli units:

∑_n=0^∞ασ((α n))
,
where the given parameter
α 
is the weight of each unit. Here, we are defining a new Bernoulli unit with a weight α for each α unit of change in the value of . Note that the underlying idea is similar to that of inverse transform sampling devroye1986non.
At the limit of α→ 0^+ we have
(η_j) ≈α∑_n=0^∞σ(η_j - (α n))

that is _j ∼(_j |η_j) is the weighted sum of active Bernoulli units. 
fig:activations(a) shows the approximation of this series for the softplus function for decreasing values of α.

###FIGURE###
< g r a p h i c s >  reconstruction of ReLU by as a series of Bernoulli units with shifted bias.
@@@FIGURE@@@




@#!S
Experiments and Discussion
@#^S

We evaluate the representation capabilities of Exp-RBM for different stochastic units in the following two sections.
Our initial attempt was to adapt Annealed Importance Sampling [AIS;][]salakhutdinov2008quantitative to Exp-RBMs. 
However, estimation of the importance sampling ratio in AIS for general Exp-RBM proved challenging. We consider two alternatives: 1) for large datasets, sec:filters qualitatively evaluates the filters learned by various units and; 2) sec:quant evaluates Exp-RBMs on a smaller
dataset where we can use indirect sampling likelihood to quantify the generative quality of the models with different activation functions.
 
Our objective here is to demonstrate that a combination of our sampling scheme with contrastive divergence (CD) training can indeed
produce generative models for a diverse choice of activation function. 

@#S!S
Learning Filters
@#S^S

###FIGURE###
< g r a p h i c s > Histogram of hidden variable activities on the MNIST test data, for different types of units. Units with heavier tails produce longer 
    strokes in fig:mnist. Note that the linear decay of activities in the log-domain correspond to exponential decay with different exponential coefficients.
@@@FIGURE@@@



###FIGURE###

###TABLE###
.690data & < g r a p h i c s > & 
.590N.Tanh & < g r a p h i c s >
                                    & .590bounded
3-3.590arcSinh & < g r a p h i c s >
                                                                                                                  & 90 log.
3-3.690SymSq & 
                                   < g r a p h i c s >
                                                                                                                  & 90   sqrt
3-3.690ReL & < g r a p h i c s >
                                                                                                                  & 90linear
3-3.690ReQ & < g r a p h i c s >
                                                                                                                  & 2*90 quadratic
.690SymQ & < g r a p h i c s >
3-3.690Sinh & < g r a p h i c s >
                                                                                                                  & 3*90 exponential
.690Exp & < g r a p h i c s >
.690Poisson & < g r a p h i c s >
3-3
@@@TABLE@@@
 Samples from the MNIST dataset (first two rows) and the filters with highest variance for different Exp-RBM stochastic units (two rows per unit type). 
    From top to bottom the non-linearities grow more rapidly, also producing features that represent longer strokes.
@@@FIGURE@@@


In this section,
we used CD
with a single Gibbs sampling step, 1000 hidden units, Gaussian visible units[Using Gaussian visible units also assumes that the input data is normalized to have a standard deviation of 1.], mini-batches and method of momentum, and selected the 
learning rate from {10^-2, 10^-3, 10^-4} using reconstruction error at the final epoch.
The MNIST handwritten digits dataset lecun1998gradient 
is a dataset of 70,000 "size-normalized and centered" binary images.
Each image is 28 × 28 pixel, and represents one of {0,1,...,9} digits. See the first row of fig:mnist for few instances from MNIST dataset.
For this dataset we use a momentum of .9 and train each model for 25 epochs. fig:mnist shows the filters of different stochastic units;
see table:units for details on different stochastic units.
Here, the units are ordered based on the asymptotic behavior of the activation function ; see the right margin of the figure.
This asymptotic change in the activation function is also evident from the hidden unit activation histogram of fig:activations(b), where the activation are produced on the test set
using the trained model.

These two figures suggest that transfer functions with faster asymptotic growth, have a more heavy-tailed distributions of
activations and longer strokes for the MNIST dataset, also hinting that they may be preferable
in learning representation [ see][]olshausen1997sparse. However, this comes at the cost of train-ability.
In particular, for all exponential units, due to occasionally large gradients, we have to reduce the learning rate to 10^-4 while the Sigmoid/Tanh unit remains stable for a learning rate of 10^-2. Other factors that affect the instability of training for exponential and quadratic Exp-RBMs are large momentum and small number of hidden units. Initialization of the weights could also play an important role, and sparse initialization
  sutskever2013importance,martens2010deep and regularization schemes goodfellow2013maxout could potentially improve the training of these models. In all experiments, we used uniformly random values in [-.01,.01] for all unit types.
In terms of training time, different Exp-RBMs that use the Gaussian noise and/or Sigmoid/Tanh units have similar computation time on both CPU and GPU.

fig:svhn(top) shows the receptive fields for the street-view house numbers (SVHN) netzer2011reading dataset. This dataset contains 600,000 images of digits in natural settings. Each image contains three RGB values for
32 × 32 pixels. fig:svhn(bottom) shows few filters obtained from
the jittered-cluttered NORB dataset lecun2004learning. NORB dataset contains 291,600 stereo 2 × (108 × 108) images of 50 toys under different lighting, angle and backgrounds. Here, we use a sub-sampled 48 × 48 variation, and report the features learned by two types of neurons. For learning from these two datasets, we increased the momentum to .95 and trained different models using up to 50 epochs.



###FIGURE###

###TABLE###
.690dataset & < g r a p h i c s > &  3*90 SVHN
.690sigmoid & < g r a p h i c s >
.690ReQU &                                  < g r a p h i c s >
.690dataset & < g r a p h i c s > 
& 3*90NORB
.690Tanh & 
< g r a p h i c s >
.690SymQU &
< g r a p h i c s >

@@@TABLE@@@
 Samples  and the receptive fields of different stochastic units for 
from the (top three rows) SVHN dataset and (bottom three rows) 48 × 48 (non-stereo) NORB dataset with jittered objects and cluttered background. Selection of the receptive fields is based on their variance.
@@@FIGURE@@@




@#S!S
Generating Samples
@#S^S

The USPS dataset hull1994database is relatively smaller dataset of 9,298, 16×16
 digits. We binarized this data and used 90%, 5% and 5% of instances for training, validation and test respectively; see fig:samples (first two rows) for instances from this dataset. We used Tanh activation function for the 16 × 16 = 256 visible units of the Exp-RBMs[Tanh unit is similar to the sigmoid/Bernoulli unit, with the difference that it is (anti)symmetric _i ∈{-.5, +.5}.]
and 500 hidden units of different types: 1) Tanh unit; 2) ReLU; 3) ReQU and 4)Sinh unit.



###FIGURE###

###TABLE###
.690dataset & < g r a p h i c s >
.690Tanh & < g r a p h i c s >
.690ReL & < g r a p h i c s >
.690ReQ & < g r a p h i c s >
.690Sinh &
< g r a p h i c s >
@@@TABLE@@@
 Samples from the USPS dataset (first two rows) and few of the consecutive samples generated from different Exp-RBMs using rates-FPCD.
@@@FIGURE@@@


We then trained these models using CD with 10 Gibbs sampling steps. 
Our choice of CD rather than 
alternatives that are known to produce better generative models, such as Persistent CD [PCD;][]tieleman2008training, fast PCD [FPCD;][]tieleman2009using and  
[rates-FPCD;][]breuleux2011quickly is due to practical reasons; these alternatives were unstable for some activation functions, while CD was always well-behaved. 
We ran CD for 10,000 epochs with three different learning rates {.05, .01,.001} for each model. Note that here, we did not use method of momentum and mini-batches in order to to minimize the number of hyper-parameters for our quantitative comparison. We used rates-FPCD [ We used 10 Gibbs sampling steps for each sample, zero decay of fast weights -- as suggested in  breuleux2011quickly -- and three different fast rates {.01, .001,.0001}.] to generate  9298 ×90/100  samples from each model --  the same number as the samples in the training set. We produce these sampled datasets every 1000 epochs.
fig:samples shows the samples generated by different models at their final epoch, for the "best choices" of sampling parameters and learning rate.


###FIGURE###
< g r a p h i c s >< g r a p h i c s >  Indirect Sampling Likelihood of the test data (left) and β^* for the density estimate (right) at different epochs (x-axis) for USPS dataset. 
@@@FIGURE@@@


We then used these samples _sample = {1,...,N=9298}, from each model to estimate the Indirect Sampling Likelihood [ISL;][]breuleux2011quickly of the validation set. For this, we built a non-parametric density estimate 
(; β) = ∑_n=1^N∏_j=1^256β^(_jn = _j) (1 - β)^(_jn≠_j)
and optimized the parameter β∈ (.5,1) to maximize the likelihood of the validation set -- that is β^* = _β ∏_∈_valid(, β). Here,  β = .5 defines a uniform distribution over all possible binary images, while for β = 1, only the training instances have a non-zero probability.

We then used the density estimate for β^* as well as the best rates-FPCD sampling parameter to evaluate the ISL of the test set.
At this point, we have an estimate of the likelihood of test data for each hidden unit type, for every 1000 iteration of CD updates. 
The likelihood of the test data using the density estimate produced directly from the training data, gives us an upper-bound on the ISL of these models.

fig:ISL presents all these quantities: for each hidden unit type, we present the results for the learning rate that achieves the highest ISL. 
The figure shows the estimated log-likelihood  (left) as well as β^* (right) as a function of the number of epochs. 
As the number of iterations increases, all models produce samples
that are more representative (and closer to the training-set likelihood). This is also consistent with β^* values getting closer to β^*_training = .93, the optimal parameter for the training set.

In general, we found stochastic units defined using ReLU and Sigmoid/Tanh to be the most numerically stable. However, for this problem, ReQU learns the best model and even by increasing the CD steps to 25 and also increasing the epochs by a factor of two we could not produce
similar results using Tanh units.  
This shows that a non-linearities outside the circle of well-known and commonly used exponential family, can sometimes produce more powerful generative models, even using an "approximate" sampling procedure.



@#!S
Conclusion
@#^S

This paper studies a subset of exponential family Harmoniums (EFH) with a single sufficient statistics for the purpose of learning generative models. 
The resulting family of distributions, Exp-RBM, gives a freedom of choice for the activation function of individual units, paralleling the freedom in discriminative training of neural networks. 
Moreover, it is possible to efficiently train arbitrary members of this family.
For this, we introduced a principled and efficient approximate sampling procedure and demonstrated 
that various Exp-RBMs can learn useful generative models and filters.

plainnatrefs

KwInputInputKwOutputOutputinitInitializefixFixTraining Exp-RBMs using contrastive divergencetraining data  = {n}_1 ≤ n ≤ N ;#CD steps; #epochs; learning rate λ; activation functions {(_i)}_i, {(_j)}_jmodel parameters  #epochspositive phase (+)
^+η_jn = ∑_i_i,j  ^+n_i  ∀ j,n using Gaussian apprx.
  ^+n_j ∼((^+ηn_j), '(^+ηn_j))   ∀ j,n^+n_j ∼(_j | ^+n)   ∀ j,n

^-n← ^+n  ∀ n 

negative phase (-)#CD steps
^-ν_in = ∑_j_i,j  ^-n_i  ∀ i,n using Gaussian apprx.
  ^-n_i ∼((^-νn_i), '(^-νn_i))   ∀ i,n^-n_j ∼(_j |n)   ∀ i,n


^-η_jn = ∑_i_i,j ^-n_i  ∀ j,n using Gaussian apprx.
  ^-n_j ∼((^-ηn_j), '(^-ηn_j))   ∀ j,n^+n_j ∼(_j | ^-n)   ∀ j,n
 _i,j←_i,j + λ ((^+_i ^+_j) - (^-_i ^-_j)  ) ∀ i,j 










